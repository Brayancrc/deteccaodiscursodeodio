{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKN2WKHLk2b0ifoVxdo23v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brayancrc/deteccaodiscursodeodio/blob/main/deteccaodiscursodeodio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo de detecção de discurso de ódio**\n",
        "\n",
        "A detecção de discurso de ódio é geralmente uma tarefa de classificação de sentimentos. Então, para treinamento, um modelo que pode classificar discurso de ódio de um certo pedaço de texto pode ser alcançado treinando-o em dados que geralmente são usados ​​para classificar sentimentos. Então, para a tarefa do modelo de detecção de discurso de ódio, usarei os dados de redes sociais."
      ],
      "metadata": {
        "id": "e4jA1iTPzhAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O conjunto de dados que usarei para o modelo de detecção de discurso de ódio consiste em um conjunto de teste e treinamento. O pacote de treinamento inclui uma lista de 31.962 tweets, um ID correspondente e uma tag 0 ou 1 para cada tweet. O sentimento específico que precisamos detectar neste conjunto de dados é se o tweet é ou não baseado em discurso de ódio."
      ],
      "metadata": {
        "id": "Fjtct9gLz1w1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Então, vamos começar com a tarefa de construir um modelo de detecção de discurso de ódio. Vou simplesmente começar lendo os conjuntos de dados usando o pacote pandas em python:"
      ],
      "metadata": {
        "id": "uDBMzFdn0WdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/DataScienceModels/train.csv\")\n",
        "print(\"Training Set:\"% train.columns, train.shape, len(train))\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/DataScienceModels/test.csv\")\n",
        "print(\"Test Set:\"% test.columns, test.shape, len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BzkcJqs0XJW",
        "outputId": "ac6705da-24a1-497b-f96c-286a5216d10d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Training Set: (31962, 3) 31962\n",
            "Test Set: (17197, 2) 17197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limpeza de Dados**\n",
        "\n",
        "Limpeza de dados é o processo de preparar dados formatados incorretamente para análise, excluindo ou modificando os dados formatados incorretamente, o que geralmente não é necessário ou útil para análise de dados, pois pode atrapalhar o processo ou fornecer resultados imprecisos. Agora, executarei o processo de limpeza de dados usando a biblioteca re em Python:"
      ],
      "metadata": {
        "id": "cWKWkjKe03H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def  clean_text(df, text_field):\n",
        "    df[text_field] = df[text_field].str.lower()\n",
        "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))\n",
        "    return df\n",
        "test_clean = clean_text(test, \"tweet\")\n",
        "train_clean = clean_text(train, \"tweet\")"
      ],
      "metadata": {
        "id": "LUPzyo7k1DHj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manipulando dados desbalanceados para o modelo de detecção de discurso de ódio**\n",
        "\n",
        "Se você analisar profundamente a tarefa em que estamos trabalhando com o contexto dos dados que estamos usando, verá que os tweets sobre discursos de ódio são comparativamente menores do que outros, então esta é uma situação de dados desbalanceados.\n",
        "\n",
        "Se ajustarmos esses dados para treinar nosso modelo de detecção de discurso de ódio, o modelo não generalizará nenhum discurso de ódio porque os dados com contexto para o discurso de ódio são muito menores do que os positivos. Então, nessa situação, precisamos preparar os dados para se ajustarem adequadamente ao nosso modelo.\n",
        "\n",
        "Há vários métodos que você pode usar para lidar com isso. Uma abordagem é usar oversampling ou downsampling. No caso de oversampling, usamos uma função que faz amostragem repetidamente, com substituição, da classe minoritária até que a classe tenha o mesmo tamanho da maioria. Vamos ver como podemos lidar com isso:"
      ],
      "metadata": {
        "id": "CiGICI1O1IFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "train_majority = train_clean[train_clean.label==0]\n",
        "train_minority = train_clean[train_clean.label==1]\n",
        "train_minority_upsampled = resample(train_minority,\n",
        "                                 replace=True,\n",
        "                                 n_samples=len(train_majority),\n",
        "                                 random_state=123)\n",
        "train_upsampled = pd.concat([train_minority_upsampled, train_majority])\n",
        "train_upsampled['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "RY_20LfO1ZO8",
        "outputId": "d43cedeb-bf09-43f8-db1f-fbde369b4e21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    29720\n",
              "0    29720\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29720</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Criando um Pipeline**\n",
        "\n",
        "Para simplicidade e reprodutibilidade do modelo de detecção de discurso de ódio, usei o pipeline do Scikit-Learn com um SGDClassifier, antes de treinar nosso modelo:"
      ],
      "metadata": {
        "id": "pJr2mFnU1jxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "pipeline_sgd = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf',  TfidfTransformer()),\n",
        "    ('nb', SGDClassifier()),])"
      ],
      "metadata": {
        "id": "1OgkT-c51oii"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Treinando o modelo de detecção de discurso de ódio**\n",
        "\n",
        "Agora, antes de treinar o modelo, vamos dividir os dados em um conjunto de treinamento e um conjunto de teste:"
      ],
      "metadata": {
        "id": "AHVnAJ361r6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_upsampled['tweet'],\n",
        "                                                    train_upsampled['label'],random_state = 0)"
      ],
      "metadata": {
        "id": "31oY9XDP1y_i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos treinar o modelo e prever os resultados no conjunto de teste usando o método de pontuação F1:"
      ],
      "metadata": {
        "id": "Jk_9cObD13TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline_sgd.fit(X_train, y_train)\n",
        "y_predict = model.predict(X_test)\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f4ReSv9134k",
        "outputId": "b74362a3-6035-4e2f-848b-53a7d2f7abc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9696605987864239"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Então obtivemos uma pontuação F1 de 0,96 por cento, o que é geralmente apreciável. Este modelo agora pode ser implantado e usado em produção."
      ],
      "metadata": {
        "id": "huopdd-D2Az1"
      }
    }
  ]
}